{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mn300/R_for_DS/blob/main/pygge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUexW0CmhlF3"
      },
      "source": [
        "# pygge - a collection of useful functions to make learning Python for satellite image analysis easy\n",
        "\n",
        "Developed by Heiko Balzter at the University of Leicester"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXnzg_pcTSEP"
      },
      "source": [
        "#import required libraries\n",
        "\n",
        "\n",
        "# the following pip install commands must be added to the main program\n",
        "'''\n",
        "!pip install rasterio\n",
        "!pip install sentinelsat\n",
        "!pip install geopandas\n",
        "!pip install rasterstats\n",
        "'''\n",
        "\n",
        "from collections import OrderedDict\n",
        "import csv\n",
        "import ee\n",
        "import fnmatch\n",
        "import geopandas as gpd\n",
        "import io\n",
        "import math\n",
        "from math import floor, ceil\n",
        "import matplotlib\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ogr\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from pyproj import Proj\n",
        "from pprint import pprint\n",
        "import random\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from rasterio import features, plot\n",
        "from rasterio.plot import show_hist, reshape_as_raster, reshape_as_image\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "from rasterstats import zonal_stats\n",
        "import requests\n",
        "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt, geojson\n",
        "from scipy import optimize\n",
        "import skimage.io as io\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "import joblib\n",
        "#from sklearn.externals import joblib # depracated\n",
        "import shutil\n",
        "import sys\n",
        "import webbrowser\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A97Yo1fqwzDP"
      },
      "source": [
        "def scale_to_uint8(x, percentiles=[0,100]):\n",
        "    '''\n",
        "    Scales an array to the range from 0-255 and converts the data type to uint8.\n",
        "    NaN values will be ignored.\n",
        "\n",
        "    Args:\n",
        "      x = input array\n",
        "      percentiles = list of length 2 of percentiles for trimming the histogram (0-100)\n",
        "\n",
        "    Returns:\n",
        "      Scaled array of uint8 data type\n",
        "    '''\n",
        "\n",
        "    x = np.float32(x)\n",
        "    amin = np.nanpercentile(x, percentiles[0])\n",
        "    amax = np.nanpercentile(x, percentiles[1])\n",
        "    anewmin = 0.0\n",
        "    anewmax = 255.0\n",
        "\n",
        "    # apply percentile thresholds\n",
        "    x[x<amin] = amin\n",
        "    x[x>amax] = amax\n",
        "\n",
        "    # scale values\n",
        "    xscaled = (x - amin) / (amax - amin) * (anewmax - anewmin) + anewmin\n",
        "\n",
        "    return(xscaled.astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adwJHfEUX8u_"
      },
      "source": [
        "def longlat2window(lon, lat, dataset):\n",
        "    \"\"\"\n",
        "    Converts a tuple of longitude and latitude coordinates into pixel locations\n",
        "    (rows, columns) in a raster and checks whether the coordinates are within\n",
        "    the raster extent.\n",
        "    If coordinates are outside the raster extent, the pixel locations will be\n",
        "    changed to make sure they stay within the raster extent.\n",
        "\n",
        "    Args:\n",
        "        lon (tuple): Tuple of min and max lon\n",
        "        lat (tuple): Tuple of min and max lat\n",
        "        dataset: Rasterio dataset\n",
        "\n",
        "    Returns:\n",
        "        rasterio.windows.Window\n",
        "    \"\"\"\n",
        "\n",
        "    # get coordinate referencing system from the raster file\n",
        "    p = Proj(dataset.crs)\n",
        "    # get geotransform\n",
        "    t = dataset.transform\n",
        "\n",
        "    # convert longitude and latitude from map coordinates to raster locations (pixel/line position)\n",
        "    xmin, ymin = p(lon[0], lat[0])\n",
        "    xmax, ymax = p(lon[1], lat[1])\n",
        "    col_min, row_min = ~t * (xmin, ymin) # uses the geotransform to convert the coordinates\n",
        "    col_max, row_max = ~t * (xmax, ymax)\n",
        "\n",
        "    # check whether the window coordinates are within the raster file bounds\n",
        "    # and adjust them to fit within the raster file if they are outside it\n",
        "    y0 = floor(row_max)\n",
        "    if y0 < 0:\n",
        "      y0 = 0\n",
        "    if y0 > dataset.height:\n",
        "      y0 = dataset.height\n",
        "    y1 = ceil(row_min)\n",
        "    if y1 < 0:\n",
        "      y1 = 0\n",
        "    if y1 > dataset.height:\n",
        "      y1 = dataset.height\n",
        "    x0 = floor(col_min)\n",
        "    if x0 < 0:\n",
        "      x0 = 0\n",
        "    if x0 > dataset.width:\n",
        "      x0 = dataset.width\n",
        "    x1 = ceil(col_max)\n",
        "    if x1 < 0:\n",
        "      x1 = 0\n",
        "    if x1 > dataset.width:\n",
        "      x1 = dataset.width\n",
        "\n",
        "    return Window.from_slices(rows=(y0, y1), cols=(x0, x1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Fttc1VinHw"
      },
      "source": [
        "def copy_and_overwrite(from_path, to_path, delete_target_dir=True):\n",
        "  '''\n",
        "  Copies the content of the directory from_path to to_path.\n",
        "  Deletes the to_path directory before copying if that option is selected.\n",
        "\n",
        "  Modified from: https://stackoverflow.com/questions/12683834/how-to-copy-directory-recursively-in-python-and-overwrite-all\n",
        "\n",
        "  Args:\n",
        "    from_path = string of source directory path to be copied\n",
        "    to_path = string of destination directory path to be copied to\n",
        "    delete_target_dir = True or False. If True, the destination directory will\n",
        "      be deleted before copying.\n",
        "  '''\n",
        "\n",
        "  if os.path.exists(to_path):\n",
        "    if delete_target_dir:\n",
        "      shutil.rmtree(to_path)\n",
        "      shutil.copytree(from_path, to_path)\n",
        "    else:\n",
        "      print(\"Error: Target directory exists and delete_target_dir is set to False.\")\n",
        "  else:\n",
        "    shutil.copytree(from_path, to_path)\n",
        "  return()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJJgDhWd8vci"
      },
      "source": [
        "# To make efficient use of Google Earth Engine from Python, we want to define some useful helper functions from https://climada-python.readthedocs.io/en/stable/tutorial/climada_util_earth_engine.html\n",
        "# Functions modified from climada.util.earth_engine module\n",
        "\n",
        "def obtain_image_landsat_composite(collection, time_range, area):\n",
        "    \"\"\" Selection of Landsat cloud-free composites in the Earth Engine library\n",
        "    See also: https://developers.google.com/earth-engine/landsat\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        image_composite (ee.image.Image)\n",
        "     \"\"\"\n",
        "    collection = ee.ImageCollection(collection)\n",
        "\n",
        "    ## Filter by time range and location\n",
        "    collection_time = collection.filterDate(time_range[0], time_range[1])\n",
        "    image_area = collection_time.filterBounds(area)\n",
        "    image_composite = ee.Algorithms.Landsat.simpleComposite(image_area, 75, 3)\n",
        "    return image_composite\n",
        "\n",
        "def obtain_image_median(collection, time_range, area):\n",
        "    \"\"\" Selection of median from a collection of images in the Earth Engine library\n",
        "    See also: https://developers.google.com/earth-engine/reducers_image_collection\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        image_median (ee.image.Image)\n",
        "     \"\"\"\n",
        "    collection = ee.ImageCollection(collection)\n",
        "\n",
        "    ## Filter by time range and location\n",
        "    collection_time = collection.filterDate(time_range[0], time_range[1])\n",
        "    image_area = collection_time.filterBounds(area)\n",
        "    image_median = image_area.median()\n",
        "    return image_median\n",
        "\n",
        "'''\n",
        "The function below has been modified to accept the cloud cover threshold as an input\n",
        "'''\n",
        "def obtain_image_sentinel(collection, time_range, area, clouds):\n",
        "    \"\"\" Selection of median, cloud-free image from a collection of images in the Sentinel 2 dataset\n",
        "    See also: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        sentinel_median (ee.image.Image)\n",
        "     \"\"\"\n",
        "\n",
        "    #First, method to remove cloud from the image\n",
        "    def maskclouds(image):\n",
        "        band_qa = image.select('QA60')\n",
        "        cloud_mask = ee.Number(2).pow(10).int()\n",
        "        cirrus_mask = ee.Number(2).pow(11).int()\n",
        "        mask = band_qa.bitwiseAnd(cloud_mask).eq(0) and(\n",
        "            band_qa.bitwiseAnd(cirrus_mask).eq(0))\n",
        "        return image.updateMask(mask).divide(10000)\n",
        "\n",
        "    sentinel_filtered = (ee.ImageCollection(collection).\n",
        "                         filterBounds(area).\n",
        "                         filterDate(time_range[0], time_range[1]).\n",
        "                         filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', clouds)).\n",
        "                         map(maskclouds))\n",
        "\n",
        "    sentinel_median = sentinel_filtered.median()\n",
        "    return sentinel_median\n",
        "\n",
        "def obtain_image_collection_sentinel(collection, time_range, area, clouds):\n",
        "    \"\"\" Selection of a cloud-free image collection in the Sentinel 2 dataset\n",
        "    See also: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\n",
        "\n",
        "    Parameters:\n",
        "        collection (): name of the collection\n",
        "        time_range (['YYYY-MT-DY','YYYY-MT-DY']): must be inside the available data\n",
        "        area (ee.geometry.Geometry): area of interest\n",
        "\n",
        "    Returns:\n",
        "        s2collect (image collection)\n",
        "     \"\"\"\n",
        "\n",
        "    #First, method to remove cloud from the image\n",
        "    def maskclouds(image):\n",
        "        band_qa = image.select('QA60')\n",
        "        cloud_mask = ee.Number(2).pow(10).int()\n",
        "        cirrus_mask = ee.Number(2).pow(11).int()\n",
        "        mask = band_qa.bitwiseAnd(cloud_mask).eq(0) and(\n",
        "            band_qa.bitwiseAnd(cirrus_mask).eq(0))\n",
        "        return image.updateMask(mask).divide(10000)\n",
        "\n",
        "    s2collect = (ee.ImageCollection(collection).\n",
        "                filterBounds(area).\n",
        "                filterDate(time_range[0], time_range[1]).\n",
        "                filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', clouds)).\n",
        "                map(maskclouds))\n",
        "\n",
        "    return s2collect\n",
        "\n",
        "def get_region(geom):\n",
        "    \"\"\"Get the region of a given geometry, needed for exporting tasks.\n",
        "\n",
        "    Parameters:\n",
        "        geom (ee.Geometry, ee.Feature, ee.Image): region of interest\n",
        "\n",
        "    Returns:\n",
        "        region (list)\n",
        "    \"\"\"\n",
        "    if isinstance(geom, ee.Geometry):\n",
        "        region = geom.getInfo()[\"coordinates\"]\n",
        "    elif isinstance(geom, ee.Feature, ee.Image):\n",
        "        region = geom.geometry().getInfo()[\"coordinates\"]\n",
        "    elif isinstance(geom, list):\n",
        "        condition = all([isinstance(item) == list for item in geom])\n",
        "        if condition:\n",
        "            region = geom\n",
        "    return region\n",
        "\n",
        "def get_url(name, image, scale, region, filePerBand=False):\n",
        "    \"\"\"It will open and download automatically a zip folder containing Geotiff data of 'image'.\n",
        "    Parameters:\n",
        "        name -  a base name to use when constructing filenames.\n",
        "        image (ee.image.Image): image to export\n",
        "        scale (int): resolution of export in meters (e.g: 30 for Landsat)\n",
        "        region (list): region of interest\n",
        "        filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
        "            Defaults to true. If false, a single GeoTIFF is produced and all\n",
        "            band-level transformations will be ignored.\n",
        "\n",
        "    Returns:\n",
        "        path (str)\n",
        "\n",
        "\n",
        "    If additional parameters are needed, see also:\n",
        "    https://github.com/google/earthengine-api/blob/master/python/ee/image.py\n",
        "\n",
        "    Args:\n",
        "        params: An object containing visualization options with the following\n",
        "          possible values:\n",
        "        name -  a base name to use when constructing filenames.\n",
        "        bands -  a description of the bands to download. Must be an array of\n",
        "            dictionaries, each with the following keys:\n",
        "          id -  the name of the band, a string, required.\n",
        "          crs -  an optional CRS string defining the band projection.\n",
        "          crs_transform -  an optional array of 6 numbers specifying an affine\n",
        "              transform from the specified CRS, in the order: xScale, yShearing,\n",
        "              xShearing, yScale, xTranslation and yTranslation.\n",
        "          dimensions -  an optional array of two integers defining the width and\n",
        "              height to which the band is cropped.\n",
        "          scale -  an optional number, specifying the scale in meters of the\n",
        "                 band; ignored if crs and crs_transform is specified.\n",
        "        crs -  a default CRS string to use for any bands that do not explicitly\n",
        "            specify one.\n",
        "        crs_transform -  a default affine transform to use for any bands that do\n",
        "            not specify one, of the same format as the crs_transform of bands.\n",
        "        dimensions -  default image cropping dimensions to use for any bands\n",
        "            that do not specify them.\n",
        "        scale -  a default scale to use for any bands that do not specify one;\n",
        "            ignored if crs and crs_transform is specified.\n",
        "        region -  a polygon specifying a region to download; ignored if crs\n",
        "            and crs_transform is specified.\n",
        "        filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
        "            Defaults to true. If false, a single GeoTIFF is produced and all\n",
        "            band-level transformations will be ignored.\n",
        "     \"\"\"\n",
        "    path = image.getDownloadURL({\n",
        "        'name':(name),\n",
        "        'scale': scale,\n",
        "        'region':(region),\n",
        "        'filePerBand': (filePerBand)\n",
        "        })\n",
        "\n",
        "    webbrowser.open_new_tab(path)\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK-DEGJ96rLg"
      },
      "source": [
        "# search Copernicus Open Data Hub\n",
        "# search Copernicus Open Data Hub\n",
        "def search_Cop_Hub(api, username, password, shapefile, datefrom, dateto, **kwargs):\n",
        "  '''\n",
        "  Carries out a search for Sentinel data on the Copernicus Open Data Hub.\n",
        "\n",
        "  Args:\n",
        "    api = string pointing to the API of the Data Hub\n",
        "    username = username for logging into the Copernicus Data Hub\n",
        "    password = password for logging into the Copernicus Data Hub\n",
        "    shapefile = string containing the path and file name of a shapefile for the search area\n",
        "    datefrom = string with the start date of the search, in the form YYYYMMDD\n",
        "    dateto = string with the end date of the search, in the same form\n",
        "    kwargs = additional keyword arguments that match the properties of the Sentinel mission, e.g.\n",
        "      for Sentinel-1:\n",
        "        platformname = name of the Sentinel platform, i.e. 'Sentinel-1'\n",
        "        producttype = product type, e.g. 'SLC' or 'GRD'\n",
        "      for Sentinel-2:\n",
        "        platformname = name of the Sentinel platform, i.e. 'Sentinel-2'\n",
        "        processinglevel = processing level of the data, e.g. 'Level-2A'\n",
        "        clouds = string with maximum cloud cover in the form '[0 TO 50]'\n",
        "\n",
        "  Returns an api object and an ordered dictionary of the search results\n",
        "\n",
        "\n",
        "  Notes:\n",
        "  Call this function like this:\n",
        "  # test functionality of S-1 query\n",
        "  kwargs = {\n",
        "            'platformname' : 'Sentinel-1',\n",
        "            'producttype' : 'GRD'\n",
        "          }\n",
        "\n",
        "  # test functionality of S-2 query\n",
        "  kwargs = {\n",
        "            'platformname' : 'Sentinel-2',\n",
        "            'processinglevel' : 'Level-2A',\n",
        "            'clouds' : '[0 TO 100]'\n",
        "          }\n",
        "\n",
        "  # do the search\n",
        "  api, products = search_Cop_Hub(api='https://apihub.copernicus.eu/apihub/',\n",
        "                                     username=username,\n",
        "                                     password=password,\n",
        "                                     shapefile=shapefile,\n",
        "                                     datefrom=datefrom,\n",
        "                                     dateto=dateto,\n",
        "                                     **kwargs)\n",
        "\n",
        "\n",
        "  '''\n",
        "\n",
        "  API = SentinelAPI(username, password, api)\n",
        "\n",
        "  # Get the shapefile layer's extent\n",
        "  extent, SpatialRef, epsg = get_shp_extent(shapefile)\n",
        "\n",
        "  # set query parameters and search the Copernicus Open Data Hub\n",
        "  kwargs['area'] = bbox(extent)\n",
        "  kwargs['date'] = (datefrom, dateto)\n",
        "  try:\n",
        "    kwargs = {'cloudcoverpercentage' if k == 'clouds' else k:v for k,v in kwargs.items()}\n",
        "  except NameError:\n",
        "    pass\n",
        "\n",
        "  print(\"Copernicus Open Access Hub search parameters:\")\n",
        "  for key, value in kwargs.items():\n",
        "    print(key, \" = \", value)\n",
        "\n",
        "  # search the Sentinel data hub API\n",
        "  products = API.query(**kwargs)\n",
        "\n",
        "  # the search returns an ordered dictionary object of the image products\n",
        "  return API, products\n",
        "\n",
        "\n",
        "def search_Cop_Hub_old(api, username, password, shapefile, datefrom, dateto,\n",
        "                   platformname, processinglevel, clouds):\n",
        "  '''\n",
        "  Carries out a search for Sentinel data on the Copernicus Open Data Hub.\n",
        "\n",
        "  Args:\n",
        "    api = string pointing to the API of the Data Hub\n",
        "    username = username for logging into the Copernicus Data Hub\n",
        "    password = password for logging into the Copernicus Data Hub\n",
        "    shapefile = string containing the path and file name of a shapefile for the search area\n",
        "    datefrom = string with the start date of the search, in the form YYYYMMDD\n",
        "    dateto = string with the end date of the search, in the same form\n",
        "    platformname = name of the Sentinel platform, e.g. 'Sentinel-2'\n",
        "    processinglevel = processing level of the data, e.g. 'Level-2A'\n",
        "    clouds = string with maximum cloud cover in the form '[0 TO 50]'\n",
        "\n",
        "  Returns an api object and an ordered dictionary of the search results\n",
        "  '''\n",
        "\n",
        "  print(\"This is the version from the practicals 2021-22 - now depracated\")\n",
        "\n",
        "  API = SentinelAPI(username, password, api)\n",
        "\n",
        "  # Get the shapefile layer's extent\n",
        "  extent, SpatialRef, epsg = get_shp_extent(shapefile)\n",
        "\n",
        "  #print(\"Extent of the shapefile: \\n\", extent)\n",
        "  #print(\"Spatial referencing information of the shapefile:\\n\", SpatialRef)\n",
        "  #print(\"EPSG code of the map projection: \", epsg)\n",
        "\n",
        "  # set query parameters and search the Copernicus Open Data Hub\n",
        "  kwargs = {\n",
        "          'area': bbox(extent),\n",
        "          'date': (datefrom, dateto),\n",
        "          'platformname': platformname,\n",
        "          'processinglevel': processinglevel,\n",
        "          'cloudcoverpercentage': clouds\n",
        "          }\n",
        "\n",
        "  # search the Sentinel data hub API\n",
        "  products = API.query(**kwargs)\n",
        "\n",
        "  # the search returns an ordered dictionary object of the image products\n",
        "  return API, products"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D8bneKd6P0M"
      },
      "source": [
        "def ee_array_to_df(arr, list_of_bands):\n",
        "    \"\"\"Transforms client-side ee.Image.getRegion array to pandas.DataFrame.\"\"\"\n",
        "    df = pd.DataFrame(arr)\n",
        "\n",
        "    # Rearrange the header.\n",
        "    headers = df.iloc[0]\n",
        "    df = pd.DataFrame(df.values[1:], columns=headers)\n",
        "\n",
        "    # Convert the data to numeric values.\n",
        "    for band in list_of_bands:\n",
        "        df[band] = pd.to_numeric(df[band], errors='coerce')\n",
        "\n",
        "    # Get acquisition date from the id column\n",
        "    df['date'] = df['id']\n",
        "\n",
        "    for i in range(len(df['date'])):\n",
        "        x0 = df['date'].values[i]\n",
        "        x1 = x0.split(\"_\")[0]\n",
        "        x2 = x1.split(\"T\")[0]\n",
        "        # print(i, df['date'][i], x2)\n",
        "        df['date'].values[i] = x2\n",
        "\n",
        "    # Keep the columns of interest.\n",
        "    df = df[['date',  'id', *list_of_bands]]\n",
        "\n",
        "    # drop all rows with NaN values in either of the bands\n",
        "    df = df.dropna(0)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPORDiXeIcYz"
      },
      "source": [
        "# Split string of format YYYYMMDD into three parts Y, M, D\n",
        "def split_YYYYMMDD(word):\n",
        "  # split into individual characters\n",
        "  chars = [char for char in word]\n",
        "  Y = np.int64(''.join(chars[0:4]))\n",
        "  M = np.int64(''.join(chars[4:6]))\n",
        "  D = np.int64(''.join(chars[6:8]))\n",
        "  return Y, M, D\n",
        "\n",
        "def julian_date(y, m, d):\n",
        "  # convert year, month, day into Julian date\n",
        "  # after https://quasar.as.utexas.edu/BillInfo/JulianDatesG.html\n",
        "  # if the month is January or February, subtract 1 from the year to get a new Y,\n",
        "  #   and add 12 to the month to get a new M.\n",
        "  #   (Thus, we are thinking of January and February as being the 13th and 14th month\n",
        "  #    of the previous year).\n",
        "  if m == 1 or m == 2:\n",
        "    m = m + 12\n",
        "    y = y - 1\n",
        "\n",
        "  # dropping the fractional part of all results of all multiplications and divisions, let\n",
        "  a = y / 100\n",
        "  b = a / 4\n",
        "  c = 2 - a + b\n",
        "  e = 365.25 * (y + 4716)\n",
        "  f = 30.6001 * (m + 1)\n",
        "\n",
        "  return math.floor(c + d + e + f - 1524.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqFbZYVDACU4"
      },
      "source": [
        "def easy_clip(rasterfile, clippedfile, extent):\n",
        "  '''\n",
        "  This function clips an input raster file to a geographic map extent.\n",
        "  rasterio offers an option called 'window' to load a subset of a raster file\n",
        "\n",
        "  Args:\n",
        "    rasterfile = directory path and file name of the input raster file\n",
        "    clippedfile = directory path and file name of the clipped output raster file\n",
        "    extent = extent object to define the clipping area\n",
        "  '''\n",
        "\n",
        "  # open the source file\n",
        "  with rasterio.open(rasterfile, 'r') as src:\n",
        "\n",
        "    # convert the shapefile extent to a rasterio window object\n",
        "    window = longlat2window((extent[0], extent[1]), (extent[2], extent[3]), src)\n",
        "    print(\"Window coordinates: \", window)\n",
        "\n",
        "    # read all bands but only for the window extent\n",
        "    arr = src.read(window=window, out_shape=(src.count, window.height, window.width))\n",
        "    print(\"Window array size: \", arr.shape)\n",
        "\n",
        "    # get the data type\n",
        "    dt = arr.dtype\n",
        "\n",
        "    # open the destination file\n",
        "    # copy metadata from source file\n",
        "    # BUT we must change the geotransform to the window with the update below\n",
        "    # https://rasterio.readthedocs.io/en/latest/topics/windowed-rw.html\n",
        "    kwargs = src.meta.copy()\n",
        "    kwargs.update({'height': window.height,\n",
        "                    'width': window.width,\n",
        "                    'transform': rasterio.windows.transform(window, src.transform),\n",
        "                    'driver': 'Gtiff',\n",
        "                    'count': src.count,\n",
        "                    'crs': src.crs,\n",
        "                    'dtype': dt\n",
        "                    })\n",
        "\n",
        "    with rasterio.open(clippedfile, 'w', **kwargs) as dst:\n",
        "      dst.write(arr)\n",
        "\n",
        "      # close the destination file\n",
        "      dst.close()\n",
        "\n",
        "    # close the sourcefile\n",
        "    src.close()\n",
        "  return()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fm_Av5gPOCh"
      },
      "source": [
        "def get_filenames(path, filepattern, dirpattern):\n",
        "  '''\n",
        "  Finds all file names in a directory for which the file name matches a certain string pattern,\n",
        "    and the directory name matches a different string pattern.\n",
        "  Args:\n",
        "    path = string indicating the path to a directory in which the search will be done\n",
        "    filepattern = string of the file name pattern to search for\n",
        "    dirpattern = string of the directory name pattern to search for\n",
        "\n",
        "  Returns:\n",
        "    a list of all found files with the full path directory\n",
        "  '''\n",
        "\n",
        "  filelist = []\n",
        "\n",
        "  for root, dirs, files in os.walk(path, topdown=True):\n",
        "    dirs[:] = [d for d in dirs]\n",
        "    for f in files:\n",
        "      if filepattern in f and dirpattern in root:\n",
        "        thisfile = os.path.join(root, f)\n",
        "        filelist.append(thisfile)\n",
        "\n",
        "  return(sorted(filelist))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXOEqrmzRRb4"
      },
      "source": [
        "def bbox(extent):\n",
        "  '''\n",
        "  Converts coordinates in the form of an extent object to a bounding box object.\n",
        "\n",
        "  Args:\n",
        "    extent = extent object to be converted to a bounding box object\n",
        "\n",
        "  Returns:\n",
        "    a polygon bounding box object\n",
        "  '''\n",
        "\n",
        "  # We need to define a helper function that creates a simply bounding box polygon from the\n",
        "  #   extent of our shapefile in the right format for the Data Hub API.\n",
        "  # Create a Polygon from the extent tuple\n",
        "  box = ogr.Geometry(ogr.wkbLinearRing)\n",
        "  box.AddPoint(extent[0],extent[2])\n",
        "  box.AddPoint(extent[1], extent[2])\n",
        "  box.AddPoint(extent[1], extent[3])\n",
        "  box.AddPoint(extent[0], extent[3])\n",
        "  box.AddPoint(extent[0],extent[2])\n",
        "  poly = ogr.Geometry(ogr.wkbPolygon)\n",
        "  poly.AddGeometry(box)\n",
        "  return poly\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV6fqc9Y48SW"
      },
      "source": [
        "def get_shp_extent(shapefile):\n",
        "  '''\n",
        "  Get the extent of the first layer, the CRS and the EPSG code from a shapefile\n",
        "\n",
        "  Args:\n",
        "    shapefile = path and filename of the shapefile *.shp\n",
        "\n",
        "  Returns:\n",
        "    extent of the shapefile\n",
        "    coordinate referencing system of the shapefile\n",
        "    EPSG code of the shapefile\n",
        "  '''\n",
        "\n",
        "  driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
        "  ds = driver.Open(shapefile, 0)\n",
        "\n",
        "  # get extent\n",
        "  lyr = ds.GetLayer()\n",
        "  extent = lyr.GetExtent()\n",
        "\n",
        "  # get projection information\n",
        "  SpatialRef = lyr.GetSpatialRef()\n",
        "\n",
        "  # get EPSG code of the CRS\n",
        "  EPSG = SpatialRef.GetAttrValue(\"AUTHORITY\", 1)\n",
        "\n",
        "  # close file\n",
        "  ds = None\n",
        "\n",
        "  return(extent, SpatialRef, EPSG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJudcKNo8hU2"
      },
      "source": [
        "def easy_warp(rasterfile, warpfile, EPSG, res=rasterio.warp.Resampling.bilinear, skip=False, xres=None, yres=None):\n",
        "  '''\n",
        "  Warp a rasterfile to the coordinate reference system defined by the EPSG code\n",
        "    and resample it to a new x and y pixel size if specified.\n",
        "  Uses the RasterIO warp function.\n",
        "\n",
        "  Args:\n",
        "    rasterfile = string with directory path and filename of the raster file\n",
        "    warpfile = string with directory path and filename of the warped destination raster file\n",
        "               (will be created if it does not exist)\n",
        "    EPSG = integer with the EPSG code of the destination coordinate referencing system\n",
        "    res = any resampling option from rasterio.warp.Resampling\n",
        "    skip = True or False. If True, existing warp files will be skipped.\n",
        "    xres (optional)= output pixel resolution in x direction\n",
        "    yres (optional)= output pixel resolution in y direction\n",
        "  '''\n",
        "  # check whether the warp file already exists and skip if it does\n",
        "  if not os.path.exists(warpfile):\n",
        "    print(\"Creating warped file:\" + warpfile)\n",
        "\n",
        "    dst_crs = 'EPSG:'+str(EPSG) # destination coordinate referencing system\n",
        "\n",
        "    with rasterio.open(rasterfile) as src:\n",
        "      transform, width, height = calculate_default_transform(\n",
        "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
        "      kwargs = src.meta.copy()\n",
        "      kwargs.update({\n",
        "        'crs': dst_crs,\n",
        "        'transform': transform,\n",
        "        'width': width,\n",
        "        'height': height\n",
        "      })\n",
        "\n",
        "      # resample data to target shape if output pixel size is specified\n",
        "\n",
        "      # get input raster resolution in x and y\n",
        "      x_input_resolution, y_input_resolution = spatial_resolution(src)\n",
        "\n",
        "      # scale in x direction\n",
        "      if xres is not None:\n",
        "        scale_factor_x = xres / x_input_resolution\n",
        "      else:\n",
        "        scale_factor_x = 1.0\n",
        "\n",
        "      # scale in y direction\n",
        "      if yres is not None:\n",
        "        scale_factor_y = yres / y_input_resolution\n",
        "      else:\n",
        "        scale_factor_y = 1.0\n",
        "\n",
        "      data = src.read(\n",
        "          out_shape=(\n",
        "              src.count,\n",
        "              int(src.height * scale_factor_y),\n",
        "              int(src.width * scale_factor_x)\n",
        "          ),\n",
        "          resampling=Resampling.bilinear\n",
        "      )\n",
        "\n",
        "      # scale image transform\n",
        "      dst_transform = src.transform * src.transform.scale(\n",
        "          (src.width / data.shape[-1]),\n",
        "          (src.height / data.shape[-2])\n",
        "      )\n",
        "\n",
        "      with rasterio.open(warpfile, 'w', **kwargs) as dst:\n",
        "        for i in range(1, src.count + 1):\n",
        "          reproject(\n",
        "            source=rasterio.band(src, i),\n",
        "            destination=rasterio.band(dst, i),\n",
        "            src_transform=src.transform,\n",
        "            src_crs=src.crs,\n",
        "            dst_transform=transform,\n",
        "            dst_crs=dst_crs,\n",
        "            resampling=res)\n",
        "\n",
        "  else:\n",
        "    print(warpfile + \" already exists. Skipping this command.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EeFoigm_YKp"
      },
      "source": [
        "def spatial_resolution(raster):\n",
        "    \"\"\"extracts the XY Pixel Size\"\"\"\n",
        "    t = raster.transform\n",
        "    x = t[0]\n",
        "    y =-t[4]\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKTEKrFwBe2v"
      },
      "source": [
        "def convert_to_dtype(rasterfile, outfile, out_dtype=np.uint8, scale=True,\n",
        "                     percentiles=[0,100], maximum=np.nan):\n",
        "  '''\n",
        "  Convert a rasterfile to the data type defined in out_dtype.\n",
        "\n",
        "  Args:\n",
        "    rasterfile = string with directory path and filename of the raster file\n",
        "    outfile = string with directory path and filename of the output raster file\n",
        "    out_dtype = output raster data type, default = np.uint8\n",
        "    scale = if True, values are scaled to 0-255\n",
        "    percentiles = values will be capped within the percentile range. Default is\n",
        "                  to use all values\n",
        "    maximum = an optional maximum value. If this is not np.nan, then the pixel\n",
        "              values will be capped at the maximum value given here instead of\n",
        "              the percentiles\n",
        "  '''\n",
        "\n",
        "  def scale_to_uint8(x, percentiles=[0,100], maximum=np.nan):\n",
        "    '''\n",
        "    Scales an array to the range from 0-255 and converts the data type to uint8.\n",
        "    NaN values will be ignored.\n",
        "\n",
        "    Args:\n",
        "      x = input array\n",
        "      percentiles = list of length 2 of percentiles for trimming the histogram (0-100)\n",
        "      maximum = an optional maximum value. If this is not np.nan, then the pixel\n",
        "                values will be capped at the maximum value given here instead of\n",
        "                the percentiles\n",
        "\n",
        "    Returns:\n",
        "      Scaled array of uint8 data type\n",
        "    '''\n",
        "\n",
        "    x = np.float32(x)\n",
        "\n",
        "    anewmin = 0.0\n",
        "    anewmax = 255.0\n",
        "\n",
        "    if np.isnan(maximum):\n",
        "      amin = np.nanpercentile(x, percentiles[0])\n",
        "      amax = np.nanpercentile(x, percentiles[1])\n",
        "    else:\n",
        "      amin = 0\n",
        "      amax = maximum\n",
        "\n",
        "    print('Scaling from ['+str(amin)+','+str(amax)+'] to [0, 255]')\n",
        "\n",
        "    # apply percentile thresholds or maximum threshold\n",
        "    x[x<amin] = amin\n",
        "    x[x>amax] = amax\n",
        "\n",
        "    # scale values\n",
        "    xscaled = (x - amin) / (amax - amin) * (anewmax - anewmin) + anewmin\n",
        "\n",
        "    return(xscaled.astype(np.uint8))\n",
        "\n",
        "  with rasterio.open(rasterfile) as src:\n",
        "    kwargs = src.meta.copy()\n",
        "    kwargs.update({\n",
        "      'dtype': out_dtype\n",
        "    })\n",
        "\n",
        "    # save the uint8 raster file\n",
        "    newfile = rasterio.open(outfile, 'w', driver=src.driver,\n",
        "                            width=src.width, height=src.height,\n",
        "                            count=src.count, crs=src.crs,\n",
        "                            transform=src.transform,\n",
        "                            dtype=out_dtype)\n",
        "\n",
        "    for i in range(1, src.count + 1):\n",
        "      band = np.array(src.read(i))\n",
        "\n",
        "      if (out_dtype == np.uint8 and ((band.min() < 0) or (band.max() > 255))) or scale:\n",
        "        band = scale_to_uint8(band, percentiles, maximum)\n",
        "\n",
        "      newfile.write(band.astype(out_dtype), i)\n",
        "\n",
        "    newfile.close()\n",
        "    src.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3l-L27oncVO"
      },
      "source": [
        "def easy_ndvi(redfile, nirfile, outfile):\n",
        "  '''\n",
        "  Calculates NDVI from a red and NIR raster band file and saves it as a Geotiff raster.\n",
        "\n",
        "  Args:\n",
        "    redfile = string of the filename and directory path to the raster file containing the red band\n",
        "    nirfile = string of the filename and directory path to the raster file containing the NIR band\n",
        "    outfile = string of the output filename and directory path for the NDVI raster file\n",
        "  '''\n",
        "\n",
        "  # open the red band file\n",
        "  redfile = rasterio.open(redfile, 'r')\n",
        "  # load the data from the red band file\n",
        "  band_red = redfile.read(1)\n",
        "\n",
        "  # open the NIR band file\n",
        "  nirfile = rasterio.open(nirfile, 'r')\n",
        "  # load the data from the NIR band file\n",
        "  band_nir = nirfile.read(1)\n",
        "\n",
        "  # The Sentinel-2 bands are delivered as uint16 data type (unsigned integer 16 bits per pixel).\n",
        "  # This means that we cannot do floating point calculations on them without first converting them to float.\n",
        "  # Convert the band arrays to float:\n",
        "  band_red = np.float32(band_red)\n",
        "  band_nir = np.float32(band_nir)\n",
        "\n",
        "  # Calculate the vegetation index. This is done pixel by pixel using the NumPy masked array arithmetic.\n",
        "\n",
        "  # We need to handle exceptions to the calculation. Where the sum of the two bands\n",
        "  # in the denominator is zero (NIR+Red), the NDVI formula would give an error otherwise.\n",
        "  # We do this by setting the NumPy error state to 'ignore' for this calculation only:\n",
        "  # https://numpy.org/doc/stable/reference/generated/numpy.errstate.html\n",
        "\n",
        "  with np.errstate(divide='ignore'): # this only applies to the following indented lines of code\n",
        "    # NDVI formula:\n",
        "    ndvi = np.divide((band_nir - band_red), (band_nir + band_red)) # ignore division by zero errors here\n",
        "    ndvi[(band_nir + band_red) == 0] = 0 # where NIR + Red is zero, set the NDVI to zero\n",
        "\n",
        "  # save the NDVI image\n",
        "  outfile = rasterio.open(outfile, 'w', driver=\"GTiff\", width=redfile.width,\n",
        "                          height=redfile.height, count=1, crs=redfile.crs,\n",
        "                          transform=redfile.transform, dtype=np.float32)\n",
        "  outfile.write(ndvi, 1)\n",
        "  outfile.close()\n",
        "\n",
        "  return()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU7a0a_ONUJQ"
      },
      "source": [
        "def easy_plot(afile, ax, bands=[3,2,1], percentiles=[0,100], cmap=\"binary_r\",\n",
        "              xlim=None, ylim=None, shapefile=None, fillcolor=None, linecolor=None,\n",
        "              title=None, fontsize=None):\n",
        "  '''\n",
        "  Visualise a raster image file in GeoTIFF format on a specified axis of a figure in matplotlib.\n",
        "  Red, Green and Blue bands for the visualisation can be specified.\n",
        "  Optionally, percentiles for cropping extreme values can be specified.\n",
        "  Also optional is the definition of x and y limits of coordinates for zooming\n",
        "  into the raster image.\n",
        "  The raster will be converted to uint8 data type for plotting.\n",
        "  Optionally, a shapefile can be plotted on top of the raster.\n",
        "\n",
        "  Args:\n",
        "    afile = string with directory path and filename of the raster file\n",
        "    ax = matplotlib axes object on which the image will be plotted\n",
        "    bands (optional) = list of three integer values specifying which bands of the\n",
        "      raster will be displayed as red, green and blue (default = [3,2,1])\n",
        "    percentiles (optional) = list of two values from 0 to 100 specifying the extreme\n",
        "      values that will be excluded from the visualisation. Default is that all\n",
        "      values will be plotted = [0,100]\n",
        "    cmap (only used for single band plots) = matplotlib colormap, defaults to reverse binary (black to white)\n",
        "    xlim (optional) = list of two x coordinate values in map units for zooming into the raster\n",
        "    ylim (optional) = list of two y coordinate values in map units for zooming into the raster\n",
        "    shapefile (optional) = string with directory path and filename of the shapefile\n",
        "    fillcolor (optional) = fill colour of the polygons from the shapefile\n",
        "    linecolor (optional) = line colour of the polygons from the shapefile\n",
        "    title (optional) = string with a plot title\n",
        "    fontsize (optional) = fontsize for the plot title\n",
        "  '''\n",
        "\n",
        "  def scale_to_uint8(x, percentiles=[0,100]):\n",
        "    '''\n",
        "    Scales an array to the range from 0-255 and converts the data type to uint8.\n",
        "    NaN values will be ignored.\n",
        "\n",
        "    Args:\n",
        "      x = input array\n",
        "      percentiles = list of length 2 of percentiles for trimming the histogram (0-100)\n",
        "\n",
        "    Returns:\n",
        "      Scaled array of uint8 data type\n",
        "    '''\n",
        "\n",
        "    x = np.float32(x)\n",
        "    amin = np.nanpercentile(x, percentiles[0])\n",
        "    amax = np.nanpercentile(x, percentiles[1])\n",
        "    anewmin = 0.0\n",
        "    anewmax = 255.0\n",
        "\n",
        "    # apply percentile thresholds\n",
        "    x[x<amin] = amin\n",
        "    x[x>amax] = amax\n",
        "\n",
        "    # scale values\n",
        "    xscaled = (x - amin) / (amax - amin) * (anewmax - anewmin) + anewmin\n",
        "\n",
        "    return(xscaled.astype(np.uint8))\n",
        "\n",
        "  # open the input raster\n",
        "  with rasterio.open(afile, 'r') as src:\n",
        "\n",
        "    # save the uint8 image as a temporary Geotiff file with only 3 bands\n",
        "    with rasterio.open('tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff',\n",
        "                        'w', driver='Gtiff', width=src.width, height=src.height,\n",
        "                        count=3, crs=src.crs, transform=src.transform,\n",
        "                        dtype=np.uint8) as tmpfile:\n",
        "\n",
        "      # mask out extreme values for each band\n",
        "      for b in range(len(bands)):\n",
        "        # read band data\n",
        "        a = src.read(bands[b])\n",
        "        a_uint8 = scale_to_uint8(a, percentiles)\n",
        "        # write the output into the new file as band b+1\n",
        "        tmpfile.write(a_uint8, b+1)\n",
        "\n",
        "    # close the files\n",
        "    tmpfile.close()\n",
        "    src.close()\n",
        "\n",
        "    # plot the raster\n",
        "    with rasterio.open(r'tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff', 'r') as imgfile:\n",
        "\n",
        "      if (xlim==None):\n",
        "        xlim=[imgfile.bounds.left, imgfile.bounds.right]\n",
        "        # afile.bounds returns a BoundingBox(left, bottom, right, top) object,\n",
        "        #    from which we need to get the corner coordinates like so\n",
        "\n",
        "      if (ylim==None):\n",
        "        ylim=[imgfile.bounds.bottom, imgfile.bounds.top]\n",
        "\n",
        "      # zoom in to an area of interest by setting the axes limits of our map\n",
        "      ax.set_xlim(xlim)\n",
        "      ax.set_ylim(ylim)\n",
        "      if len(bands) == 1:\n",
        "        rasterio.plot.show(imgfile.read(bands[0]), ax=ax, cmap=cmap, transform=imgfile.transform)\n",
        "      else:\n",
        "        rasterio.plot.show(imgfile, ax=ax, transform=imgfile.transform)\n",
        "\n",
        "      # close the temporary file\n",
        "      imgfile.close()\n",
        "\n",
        "    # and remove the temporary file when we do not need it anymore\n",
        "    os.remove('tmp_rgb_imagefile_ cjdlsbYFEOGFHEWBVUW.tiff')\n",
        "\n",
        "  # Use the Geopandas library for plotting the shapefile on top of the raster image,\n",
        "  #   if a shapefile name is defined\n",
        "  if shapefile is not None:\n",
        "    shp = gpd.read_file(shapefile)\n",
        "\n",
        "    if fillcolor is None:\n",
        "      fillcolor = \"none\"\n",
        "\n",
        "    if linecolor is None:\n",
        "      linecolor = \"yellow\"\n",
        "\n",
        "    shp.plot(ax=ax, facecolor=fillcolor, edgecolor=linecolor)\n",
        "\n",
        "  # add an optional title for the plot if one is given\n",
        "  if fontsize is None:\n",
        "    fontsize = 8\n",
        "\n",
        "  ax.set_title(title, fontsize=fontsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsjOj300ddOs"
      },
      "source": [
        "def sample_raster(afile, band=1, n=1000, missing=65535):\n",
        "  '''\n",
        "  Draws a random sample of n pixel values from a raster but excludes missing values.\n",
        "  Sampling is done without replacement.\n",
        "  Returns a list of pixel values for a single band.\n",
        "  Pixel locations are recorded in the function but are not currently returned.\n",
        "\n",
        "  Args:\n",
        "    afile = file name of the raster file\n",
        "    band = number of the single band to be sampled\n",
        "    n = number of samples\n",
        "    missing = No Data value in the raster\n",
        "  '''\n",
        "\n",
        "  random.seed(1)\n",
        "\n",
        "  pxs = [] # list of pixel coordinates in x\n",
        "  pys = [] # list of pixel coordinates in y\n",
        "  vals = [] # list of pixel values\n",
        "\n",
        "  dataset = rasterio.open(afile, 'r')\n",
        "\n",
        "  while True:\n",
        "\n",
        "    # generate a random pixel coordinate pair\n",
        "    px = int(random.random()*dataset.width)\n",
        "    py = int(random.random()*dataset.height)\n",
        "\n",
        "    # create 1x1px window of the pixel\n",
        "    window = rasterio.windows.Window(px - 1//2, py - 1//2, 1, 1)\n",
        "\n",
        "    # read rgb values of the single-pixel window but exclude missing values\n",
        "    clip = dataset.read(band, window=window)\n",
        "\n",
        "    if clip[0][0] != missing:\n",
        "      if px not in pxs and py not in pys:\n",
        "        vals.append(clip[0][0])\n",
        "        pxs.append(px)\n",
        "        pxs.append(py)\n",
        "\n",
        "    if len(vals)==n:\n",
        "      break\n",
        "\n",
        "  return(vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD2PvsSE1IF0"
      },
      "source": [
        "def hist_sample(imagefile, n=1000, missing=65535, title=\"histogram\", **kwargs):\n",
        "  '''\n",
        "  shows a histogram of a pixel sample from a raster image file with one or more bands\n",
        "\n",
        "  Args:\n",
        "    imagefile = path and file name of the raster image\n",
        "    n (optional) = sample size\n",
        "    missing (optional) = missing value to be excluded from the histogram plot\n",
        "    title (optional) = plot title\n",
        "    kwargs (optional) = optional parameters for Matplotlib\n",
        "\n",
        "  Returns a figure and axes object\n",
        "  '''\n",
        "\n",
        "  # unpack the keyword arguments for the figure object\n",
        "  fig_kwargs = {\"figsize\" : kwargs.get(\"figsize\", (6,6)),\n",
        "                \"dpi\" : kwargs.get(\"dpi\", None),\n",
        "                \"facecolor\" : kwargs.get(\"facecolorfig\", \"white\"),\n",
        "                \"edgecolor\" : kwargs.get(\"edgecolor\", \"black\"),\n",
        "                \"linewidth\" : kwargs.get(\"linewidth\", 1),\n",
        "                \"frameon\" : kwargs.get(\"frameon\", None),\n",
        "                \"subplotpars\" : kwargs.get(\"subplotpars\", None),\n",
        "                \"tight_layout\" : kwargs.get(\"tight_layout\", None),\n",
        "                \"constrained_layout\" : kwargs.get(\"constrained_layout\", None)\n",
        "                }\n",
        "\n",
        "  # unpack the keyword arguments for the axes.hist object\n",
        "  hist_kwargs = {\"bins\" : kwargs.get(\"bins\", 20),\n",
        "                 \"range\" : kwargs.get(\"range\", None),\n",
        "                 \"density\" : kwargs.get(\"density\", None),\n",
        "                 \"weights\" : kwargs.get(\"weights\", None),\n",
        "                 \"cumulative\" : kwargs.get(\"cumulative\", False),\n",
        "                 \"bottom\" : kwargs.get(\"bottom\", None),\n",
        "                 \"histtype\" : kwargs.get(\"histtype\", \"bar\"),\n",
        "                 \"align\" : kwargs.get(\"align\", \"mid\"),\n",
        "                 \"orientation\" : kwargs.get(\"orientation\", \"vertical\"),\n",
        "                 \"log\" : kwargs.get(\"log\", False),\n",
        "                 \"color\" : kwargs.get(\"color\", \"skyblue\"),\n",
        "                 \"label\" : kwargs.get(\"label\", None),\n",
        "                 \"stacked\" : kwargs.get(\"stacked\", False),\n",
        "                 \"data\" : kwargs.get(\"data\", None),\n",
        "                 \"linewidth\" : kwargs.get(\"linewidth\", 1),\n",
        "                 \"antialiased\" : kwargs.get(\"antialiased\", None),\n",
        "                 \"hatch\" : kwargs.get(\"hatch\", None),\n",
        "                 \"fill\" : kwargs.get(\"fill\", True),\n",
        "                 \"capstyle\" : kwargs.get(\"capstyle\", \"round\"),\n",
        "                 \"joinstyle\" : kwargs.get(\"joinstyle\", \"miter\"),\n",
        "                 \"agg_filter\" : kwargs.get(\"agg_filter\", None),\n",
        "                 \"alpha\" : kwargs.get(\"alpha\", None),\n",
        "                 \"clip_box\" : kwargs.get(\"clip_box\", None),\n",
        "                 \"clip_on\" : kwargs.get(\"clip_on\", None),\n",
        "                 \"clip_path\" : kwargs.get(\"clip_path\", None),\n",
        "                 \"gid\" : kwargs.get(\"gid\", None),\n",
        "                 \"edgecolor\" : kwargs.get(\"edgecolor\", None),\n",
        "                 \"facecolor\" : kwargs.get(\"facecolorhist\", None),\n",
        "                 \"in_layout\" : kwargs.get(\"in_layout\", False),\n",
        "                 \"linestyle\" : kwargs.get(\"linestyle\", \"-\"),\n",
        "                 \"rasterized\" : kwargs.get(\"rasterized\", None),\n",
        "                 \"snap\" : kwargs.get(\"snap\", None),\n",
        "                 \"url\" : kwargs.get(\"url\", None),\n",
        "                 \"visible\" : kwargs.get(\"visible\", True),\n",
        "                 \"zorder\" : kwargs.get(\"zorder\", None)\n",
        "                  }\n",
        "\n",
        "  # get number of bands\n",
        "  ds = rasterio.open(imagefile, 'r')\n",
        "  bands = ds.count\n",
        "  ds = None\n",
        "\n",
        "  # create a figure and axes object\n",
        "  fig, ax = plt.subplots(1, bands, **fig_kwargs)\n",
        "\n",
        "  for b in range(bands):\n",
        "    print(b)\n",
        "    # sample the raster bands\n",
        "    pixels = sample_raster(imagefile, b+1, n, missing)\n",
        "\n",
        "    # plot the histograms\n",
        "    t = title + '_' + str(b+1)\n",
        "    ax[b].hist(pixels, **hist_kwargs)\n",
        "\n",
        "    # add a title if specified\n",
        "    if t is not None:\n",
        "      ax[b].set_title(t)\n",
        "\n",
        "  return(fig, ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEXDyhtdJfCd"
      },
      "source": [
        "def training_shapefile_to_raster(training_shapefilename, inraster_filename, outraster_filename, verbose=False):\n",
        "  '''\n",
        "  Reads in a shapefile with training polygons and produces a raster file that\n",
        "    aligns with an input rasterfile (same corner coordinates, resolution, coordinate\n",
        "    reference system and geotransform). Each pixel value in the output raster will\n",
        "    indicate the class number of the training shapefile based on the attribute column\n",
        "    named 'Class' with a capital C.\n",
        "\n",
        "  Based on https://gis.stackexchange.com/questions/151339/rasterize-a-shapefile-with-geopandas-or-fiona-python\n",
        "\n",
        "  Args:\n",
        "    training_shapefilename = string pointing to the input training shapefile in ESRI format\n",
        "    inraster_filename = string pointing to the input raster file that we want to align the output raster to\n",
        "    outraster_filename = string pointing to the output raster file\n",
        "    verbose (optional)= True or False. If True, additional text output will be printed.\n",
        "  '''\n",
        "\n",
        "  # Open the shapefile with GeoPANDAS\n",
        "  shp = gpd.read_file(training_shapefilename)\n",
        "\n",
        "  # Open the input raster file with RasterIO\n",
        "  inraster = rasterio.open(inraster_filename, 'r')\n",
        "  # Reproject the geometries from the shapefile to the CRS of the raster\n",
        "  shp = shp.to_crs(inraster.crs)\n",
        "\n",
        "  # copy and update the metadata from the input raster for the output\n",
        "  meta = inraster.meta.copy()\n",
        "  meta.update(dtype=np.uint8)\n",
        "  meta.update(count=1)\n",
        "\n",
        "  # Now burn the features into the raster and write it\n",
        "  with rasterio.open(outraster_filename, 'w', **meta) as outraster:\n",
        "    # create the output array as a Numpy array filled with zeros and of the same\n",
        "    #    shape as the input raster\n",
        "    raster_shape = inraster.read(1).shape\n",
        "    out_arr = np.zeros(raster_shape, dtype=np.uint8)\n",
        "\n",
        "    # this is where we create a generator of geom, value pairs to use in rasterizing\n",
        "    shapes = ((geom, value) for geom, value in zip(shp.geometry, shp.Class))\n",
        "    burned = features.rasterize(shapes=shapes, fill=0, out=out_arr,\n",
        "                                transform=outraster.transform, all_touched=False)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Shapefile attribute table and polygon geometries:\")\n",
        "      pprint(shp)\n",
        "\n",
        "      print(\"shapes is a generator object:\")\n",
        "      print(shapes)\n",
        "\n",
        "      print(\"class values and geometries:\")\n",
        "      for geom, value in zip(shp.geometry, shp.Class):\n",
        "        print(value, geom)\n",
        "\n",
        "      print(\"Rasterised layer:\")\n",
        "      print(burned)\n",
        "\n",
        "      print(\"The output raster has values from \", np.min(burned), \" to \", np.max(burned))\n",
        "\n",
        "    outraster.write(burned.astype(np.uint8), 1)\n",
        "    outraster = None\n",
        "\n",
        "  inraster = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7woShvarKdh"
      },
      "source": [
        "def train_rf_model(raster, samples, modelfile, ntrees = 101, weights = None):\n",
        "    '''\n",
        "    Trains a random forest classifier model based on a raster file with bands\n",
        "      as features and a second raster file with training data, in which pixel\n",
        "      values indicate the class.\n",
        "\n",
        "    Args:\n",
        "      raster = filename and path to the raster file to be classified in tiff format\n",
        "      samples = filename and path to the raster file with the training samples\n",
        "        as pixel values (in tiff format)\n",
        "      modelfile = filename and path to a pickle file to save the trained model to\n",
        "      ntrees (optional) = number of trees in the random forest, default = 101\n",
        "      weights (optional) = a list of integers giving weights for all classes.\n",
        "        If not specified, all weights will be equal.\n",
        "\n",
        "    Returns:\n",
        "      random forest model object\n",
        "    '''\n",
        "\n",
        "    # read in raster from geotiff\n",
        "    img_ds = io.imread(raster)\n",
        "\n",
        "    # convert to 16bit numpy array\n",
        "    img = np.array(img_ds, dtype='int16')\n",
        "\n",
        "    # read in the training sample pixels\n",
        "    roi_ds = io.imread(samples)\n",
        "    roi = np.array(roi_ds, dtype='int8')\n",
        "\n",
        "    # read in the class labels\n",
        "    labels = np.unique(roi[roi > 0])\n",
        "    nclasses = labels.size # number of unique class values\n",
        "    print('The training data include {n} classes: {classes}'.format(n=nclasses, classes=labels))\n",
        "\n",
        "    # compose the X,Y pixel positions (feature dataset and training dataset)\n",
        "    # 0 = missing class value\n",
        "    X = img[roi > 0, :]\n",
        "    Y = roi[roi > 0]\n",
        "\n",
        "    # create a dictionary of class weights (class 1 has the weight 1, etc.)\n",
        "    w = dict() # create an empty dictionary\n",
        "    for i in range(nclasses): # iterate over all classes from 0 to nclasses-1\n",
        "      if weights == None:\n",
        "        w[i+1] = '1' # if not specified, set all weights to 1\n",
        "      else:\n",
        "        if weights.size >= nclasses: # if enough weights are given, assign them\n",
        "          w[i+1] = weights[i] # assign the weights if specified by the user\n",
        "        else: # if fewer weights are defined than the number of classes, then set the remaining weights to 1\n",
        "          if i > weights.size:\n",
        "            w[i+1] = '1' # set weight to 1\n",
        "          else:\n",
        "            w[i+1] = weights[i] # assign the weights if specified by the user\n",
        "\n",
        "    # build the Random Forest Classifier\n",
        "    # for more information: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "    rf = RandomForestClassifier(class_weight = weights, n_estimators = ntrees, criterion = 'gini', max_depth = 4,\n",
        "                                min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto',\n",
        "                                bootstrap = True, oob_score = True, n_jobs = 1, random_state = None, verbose = True)\n",
        "\n",
        "    # fit the model to the training data and the feature dataset\n",
        "    rf = rf.fit(X,Y)\n",
        "\n",
        "    # export the Random Forest model to a file\n",
        "    joblib.dump(rf, modelfile)\n",
        "\n",
        "    # calculate the feature importances\n",
        "    importances = rf.feature_importances_\n",
        "    std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    # Print the feature ranking\n",
        "    print(\"Feature ranking:\")\n",
        "    for f in range(X.shape[1]):\n",
        "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "    # Plot the feature importances of the forest\n",
        "    plt.figure()\n",
        "    plt.title(\"Feature importances\")\n",
        "    plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(X.shape[1]), indices)\n",
        "    plt.xlim([-1, X.shape[1]])\n",
        "    plt.show()\n",
        "\n",
        "    # Out-of-bag error rate as a function of number of trees:\n",
        "    oob_error = [] # define an empty list with pairs of values\n",
        "\n",
        "    # Range of `n_estimators` values to explore.\n",
        "    mintrees = 30 # this needs to be a sensible minimum number to get reliable OOB error estimates\n",
        "    maxtrees = max(mintrees, ntrees) # go all the way to the highest number of trees\n",
        "    nsteps = 5 # number of steps to calculate OOB error rate for (saves time)\n",
        "\n",
        "    # work out the error rate for each number of trees in the random forest\n",
        "    for i in range(mintrees, maxtrees + 1, round((maxtrees - mintrees)/nsteps)): # start, end, step\n",
        "      rf.set_params(n_estimators=i)\n",
        "      rf.fit(X, Y)\n",
        "      oob_error.append((i, 1 - rf.oob_score_))\n",
        "\n",
        "    # Plot OOB error rate vs. number of trees\n",
        "    xs, ys = zip(*oob_error)\n",
        "    plt.plot(xs, ys)\n",
        "    # plt.xlim(0, maxtrees)\n",
        "    plt.xlabel(\"n_estimators\")\n",
        "    plt.ylabel(\"OOB error rate\")\n",
        "    # plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "    return(rf) # returns the random forest model object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0YniMeTrjjy"
      },
      "source": [
        "def classify_rf(raster, modelfile, outfile, verbose = False):\n",
        "  '''\n",
        "  Reads in a pickle file of a random forest model and a raster file with feature layers,\n",
        "    and classifies the raster file using the model.\n",
        "\n",
        "  Args:\n",
        "    raster = filename and path to the raster file to be classified (in tiff uint16 format)\n",
        "    modelfile = filename and path to the pickled file with the random forest model in uint8 format\n",
        "    outfile = filename and path to the output file with the classified map in uint8 format\n",
        "    verbose (optional) = True or False. If True, provides additional printed output.\n",
        "  '''\n",
        "\n",
        "  # Read Data\n",
        "  src = rasterio.open(raster, 'r')\n",
        "  img = src.read()\n",
        "\n",
        "  if verbose:\n",
        "    print(\"img.shape = \", img.shape)\n",
        "\n",
        "  # get number of bands\n",
        "  n = img.shape[0]\n",
        "\n",
        "  if verbose:\n",
        "    print(n, \" Bands\")\n",
        "\n",
        "  # load your random forest model from the pickle file\n",
        "  clf = joblib.load(modelfile)\n",
        "\n",
        "  # to work with SciKitLearn, we have to reshape the raster as an image\n",
        "  # this will change the shape from (bands, rows, columns) to (rows, columns, bands)\n",
        "  img = reshape_as_image(img)\n",
        "\n",
        "  # next, we have to reshape the image again into (rows * columns, bands)\n",
        "  # because that is what SciKitLearn asks for\n",
        "  new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
        "\n",
        "  if verbose:\n",
        "    print(\"img[:, :, :n].shape = \", img[:, :, :n].shape)\n",
        "    print(\"new_shape = \", new_shape)\n",
        "\n",
        "  img_as_array = img[:, :, :n].reshape(new_shape)\n",
        "\n",
        "  if verbose:\n",
        "    print(\"img_as_array.shape = \", img_as_array.shape)\n",
        "\n",
        "  # classify it\n",
        "  class_prediction = clf.predict(img_as_array)\n",
        "\n",
        "  # and reshape the flattened array back to its original dimensions\n",
        "  if verbose:\n",
        "    print(\"class_prediction.shape = \", class_prediction.shape)\n",
        "    print(\"img[:, :, 0].shape = \", img[:, :, 0].shape)\n",
        "\n",
        "  class_prediction = np.uint8(class_prediction.reshape(img[:, :, 0].shape))\n",
        "\n",
        "  if verbose:\n",
        "    print(class_prediction.dtype)\n",
        "\n",
        "  # save the image as a uint8 Geotiff file\n",
        "  tmpfile = rasterio.open(outfile, 'w', driver='Gtiff',\n",
        "                          width=src.width, height=src.height,\n",
        "                          count=1, crs=src.crs, transform=src.transform,\n",
        "                          dtype=np.uint8)\n",
        "\n",
        "  tmpfile.write(class_prediction, 1)\n",
        "\n",
        "  tmpfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH0PejD99Y0h"
      },
      "source": [
        "def easy_plot_landcovermap(classfile, ax, shapefile=None, band=1, xlim=None, ylim=None,\n",
        "                           labels=None, colours=None, verbose=False):\n",
        "  '''\n",
        "  Visualise a raster image file on a specified axis of a figure in matplotlib.\n",
        "  The specified band must contain class values in uint8 data type.\n",
        "  Optionally, x and y limits of a coordinate window for zooming in can be given.\n",
        "  Inspired by https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/classify-plot-raster-data-in-python/\n",
        "\n",
        "  Args:\n",
        "    afile = string with directory path and filename of the raster file\n",
        "    ax = matplotlib axes object on which the image will be plotted\n",
        "    shapefile (optional) = string with directory path and filename of a shapefile to be plotted on top of the raster\n",
        "    band (optional) = number of the band containing the classes, default = 1\n",
        "    xlim (optional) = list of two x coordinate values in map units for zooming into the raster\n",
        "    ylim (optional) = list of two y coordinate values in map units for zooming into the raster\n",
        "    labels (optional) = list of class labels of the land cover classes in string format\n",
        "    colours (optional) = list of colours for the land cover classes. See this chart\n",
        "      for information on available colours: https://matplotlib.org/2.0.0/examples/color/named_colors.html\n",
        "      Example:\n",
        "        colours = ['mediumblue', 'firebrick', 'red', 'yellowgreen', 'gold', 'saddlebrown',\n",
        "          'darkolivegreen']\n",
        "    verbose (optional) = True or False. If True, additional printed output will be produced\n",
        "  '''\n",
        "\n",
        "  # open the rasterfile\n",
        "  imgfile = rasterio.open(classfile, 'r')\n",
        "\n",
        "  # read the band with the class values\n",
        "  img = np.array(imgfile.read(band), dtype=np.uint8)\n",
        "\n",
        "\n",
        "  # fix labels and colours - one label and one colour for each class in the raster\n",
        "  unq = np.unique(img[img > 0]) # all unique values, excluding zero\n",
        "\n",
        "  if labels is None:\n",
        "    labels = np.unique(img[img > 0])\n",
        "    nclasses = len(labels) # number of unique class values\n",
        "  else:\n",
        "    if len(labels) < len(unq): # if not enough labels have been defined by the user\n",
        "      for i in range(len(labels), len(unq)):\n",
        "        labels.append(\"class\"+str(unq[i]))\n",
        "    nclasses = len(labels) # number of unique class values\n",
        "\n",
        "  if colours is None:\n",
        "    cmap = cm.get_cmap('viridis', nclasses) # make a colormap with one color per class\n",
        "  else:\n",
        "    cmap = cm.get_cmap('viridis', nclasses) # make a colormap with one color per class\n",
        "    if len(colours) < nclasses: # if not enough colours have been defined by the user\n",
        "      additional_colours = plt.cm.get_cmap('viridis', nclasses-colours.size)\n",
        "        # Map each index in 0, 1, ..., n-1 to a distinct RGB color.\n",
        "        # The keyword argument name must be a standard mpl colormap name\n",
        "      colours.append(additional_colours)\n",
        "\n",
        "  print('The training data include {n} classes: {classes}'.format(n=nclasses, classes=labels))\n",
        "\n",
        "  # calculate the bin boundaries between class values, e.g. 0.5-1.5 for class 1\n",
        "  class_bins = [i+0.5 for i in range(nclasses+1)]\n",
        "\n",
        "  # Generate a colourmap index based on discrete intervals\n",
        "  norm = matplotlib.colors.BoundaryNorm(class_bins, nclasses)\n",
        "\n",
        "  # set a title for the plot\n",
        "  mytitle = \"Land cover map\"\n",
        "\n",
        "  # zoom in if xlim and ylim are specified\n",
        "  if (xlim==None):\n",
        "    xlim=[imgfile.bounds.left, imgfile.bounds.right]\n",
        "    # afile.bounds returns a BoundingBox(left, bottom, right, top) object,\n",
        "    #    from which we need to get the corner coordinates like so\n",
        "  if (ylim==None):\n",
        "    ylim=[imgfile.bounds.bottom, imgfile.bounds.top]\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_ylim(ylim)\n",
        "\n",
        "  # Plot the classified land cover raster\n",
        "  rasterio.plot.show(imgfile, ax=ax, cmap=cmap, norm=norm, title=mytitle)\n",
        "  imgfile.close()\n",
        "\n",
        "  if shapefile is not None:\n",
        "    # use the Geopandas library for plotting the shapefile\n",
        "    shp = gpd.read_file(shapefile)\n",
        "    shp.plot(ax=ax, facecolor=\"none\", edgecolor=\"black\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61A0jP7xgn7U"
      },
      "source": [
        "def easy_zonal_stats(rasterfiles, shapefile, statisticsfile, nodata=0,\n",
        "                     stats=\"count min mean max median\"):\n",
        "  '''\n",
        "  Extracts zonal statistics using rasterstats from a list of raster files and saves\n",
        "    a single statisticsfile in .csv format as output.\n",
        "\n",
        "  Args:\n",
        "    rasterfiles = list of strings with raster file names with full direcroy paths\n",
        "    shapefile = string giving the path and file name of the shapefile\n",
        "    statisticsfile = string with the name of the output .csv file\n",
        "    nodata (optional) = nodata value to be ignored in the calculation\n",
        "    stats (optional) = string defining which statistics are calculated\n",
        "\n",
        "  Returns: a Pandas dataframe with the statistics results saved into the statisticsfile\n",
        "  '''\n",
        "\n",
        "  # iterate over all raster files and extract zonal statistics\n",
        "  for x in range(len(rasterfiles)):\n",
        "    f = rasterfiles[x]\n",
        "    # extract the string between the last slash and the dot in the file name and directory path as scene ID\n",
        "    scene_id = f.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    # get zonal statistics for all polygons in the shapefile\n",
        "    # the result is a list of dictionaries\n",
        "    statistics = zonal_stats(shapefile, f, nodata=nodata, stats=stats)\n",
        "\n",
        "    # get number of rows for the output file as the product of n * m\n",
        "    n = len(statistics) # number of polygons\n",
        "    m = len(rasterfiles) # number of files\n",
        "\n",
        "    if x == 0:\n",
        "      # create the pandas dataframe in the first iteration with column names only\n",
        "      df = pd.DataFrame(columns=['scene_id'].append(stats.split(\" \")))\n",
        "\n",
        "    # add the scene ID to each row in the statistics output from this scene (image)\n",
        "    for row in range(n):\n",
        "      statistics[row].update({\"scene_id\": scene_id})\n",
        "\n",
        "    # append rows to the dataframe in each iteration with the scene_id as index\n",
        "    for s in statistics: # iterate over the list of dictionaries (one for each polygon)\n",
        "      df = df.append(s, ignore_index=True)\n",
        "\n",
        "  # After the loop, write the statistics dataframe to a .csv file (overwrite if exists)\n",
        "  df.to_csv(statisticsfile, index=False)\n",
        "\n",
        "  return(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nSxbtCtnYhO"
      },
      "source": [
        "def remove_radiometric_offset_from_N0400(in_file,\n",
        "                                         BOA_ADD_OFFSET = 1000):\n",
        "    \"\"\"\n",
        "    This function is losely based on a function written by Dr Ivan Reading, 2022-06-07\n",
        "    It fixes a data inconsistency in the Sentinel-2 time series introduced in March 2022:\n",
        "    Since processing baseline 04.00, there is a radiometric constant added to each band.\n",
        "    This function reads in an image in a recognised format and removes that constant.\n",
        "    More information can be found at:\n",
        "    https://forum.step.esa.int/t/info-introduction-of-additional-radiometric-offset-in-pb04-00-products/35431\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_file : str\n",
        "        Path to the input raster file. It must be in a Sentinel-2 SAFE file directory\n",
        "    BOA_ADD_OFFSET : int\n",
        "        Required offset per band (from xml information within L2A SAFE file directory)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    out_file : str\n",
        "        The path to the output image file\n",
        "\n",
        "    \"\"\"\n",
        "    def get_processing_baseline(file_path):\n",
        "      # works if safe_path contains the full SAFE directory name and\n",
        "      #   points to a .jp2 file with the band data\n",
        "\n",
        "      # get baseline from the SAFE file directory name\n",
        "      safe_id = file_path.split(\"/\")[-6]\n",
        "      baseline = safe_id.split(\"_\")[3].split(\".\")[0]\n",
        "\n",
        "      # if a baseline is included in the image file name, use that instead\n",
        "      # this will start with the letter A and indicate that the file has\n",
        "      # already been offset corrected\n",
        "      file_name_start = file_path.split(\"/\")[-1]\n",
        "      file_baseline = file_name_start.split(\"_\")[-1].split(\".\")[0]\n",
        "      if file_baseline.startswith('A'):\n",
        "        return file_baseline\n",
        "      else:\n",
        "        return baseline\n",
        "\n",
        "    def set_processing_baseline(file_path, new_baseline):\n",
        "      # Appends a letter 'A' and the processing baseline to the file name\n",
        "      file_path_dir = os.path.split(file_path)[0]\n",
        "      file_path_start = os.path.split(file_path)[1].split(\".\")[0]\n",
        "      file_path_end = os.path.split(file_path)[1].split(\".\")[1]\n",
        "      new_file_path = os.path.join(file_path_dir,\n",
        "                                   file_path_start + \"_\" + new_baseline + \".\" + file_path_end)\n",
        "      return new_file_path\n",
        "\n",
        "    def add_number_to_band(x, offset):\n",
        "      '''\n",
        "      Adds an offset value to each pixel in an array.\n",
        "\n",
        "      Args:\n",
        "        x = input array\n",
        "        offset = a number that will be added to each pixel value in x.\n",
        "                 Must be the same data type as the array x\n",
        "\n",
        "      Returns:\n",
        "        array (if the function runs OK)\n",
        "        -1 as an error code if the data types do not match\n",
        "      '''\n",
        "\n",
        "      #if x.dtype != np.dtype(offset):\n",
        "      #  print(\"ERROR: Offset must be of same data type as array.\")\n",
        "      #  return(-1)\n",
        "      #else:\n",
        "      x = np.float32(x)\n",
        "      x1 = x + offset\n",
        "      return(x1)\n",
        "\n",
        "    # Check out_file exists and report an error if not\n",
        "    print(\"Removing radiometric offset from processing baseline N0400 onwards.\")\n",
        "    if not os.path.exists(in_file):\n",
        "      print(\"ERROR: File does not exist: \"+in_file)\n",
        "      return -1\n",
        "    else:\n",
        "      #TODO: Read individual BOA_ADD_OFFSET value for each band from xml information in SAFE file root\n",
        "      # get the file name and remove the directory path\n",
        "      f = os.path.split(in_file)[1]\n",
        "      # detect file driver of input file\n",
        "      driver = rasterio.drivers.driver_from_extension(f)\n",
        "      # extract string of processing baseline from file name\n",
        "      baseline = get_processing_baseline(in_file)[1:]\n",
        "      if get_processing_baseline(in_file)[0] == 'A':\n",
        "        print(f'Offset already applied - file marked as: {get_processing_baseline(in_file)}')\n",
        "        return(in_file)\n",
        "      else:\n",
        "        if int(baseline) >= 400:\n",
        "          print(f'Removing radiometric offset from file: {f}')\n",
        "          print(f'Processing baseline: {baseline}')\n",
        "          # create a name for the output file\n",
        "          out_file = set_processing_baseline(in_file, f'A{baseline:s}')\n",
        "          print(f'Output file: {out_file}')\n",
        "          # open the input raster file\n",
        "          with rasterio.open(in_file, 'r') as src:\n",
        "            # get number of bands in the input raster file\n",
        "            bands = src.count\n",
        "            # create the output file\n",
        "            with rasterio.open(out_file, 'w', driver=driver, width=src.width,\n",
        "                              height=src.height, count=bands, crs=src.crs,\n",
        "                              transform=src.transform, dtype=src.dtypes[0]) as dst:\n",
        "              for band in range(bands):\n",
        "                # read band data\n",
        "                a = src.read(band+1)\n",
        "                # add the offset\n",
        "                a1 = add_number_to_band(a, BOA_ADD_OFFSET)\n",
        "                # write the band to the output file\n",
        "                dst.write(a1, band+1)\n",
        "              # close the files\n",
        "              dst.close()\n",
        "              src.close()\n",
        "              return out_file\n",
        "        else:\n",
        "          print('Offset does not need to be applied. Processing baseline is below 04.00')\n",
        "          return in_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0kdLpD0YvAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}